# Introduction

Hello and welcome to the ORBIT dataset project! 

We are collecting a dataset to help develop AI recognition apps that will use your mobile phone's camera to find and identify the things that are important to you. For example, has someone moved your house keys? Do you regularly need to identify specific items while out shopping? What about your guide cane - have you forgotten where you put it, or gotten it confused with someone else’s? Maybe you want to recognise the door of a friend’s house? Imagine if you did not have to know exactly where your things were in order to find or identify them again. 

To build these recognition apps, a large dataset of videos taken by blind and visually impaired users is needed. As part of the ORBIT dataset project, you will be asked to take multiple videos of at least ten things that are meaningful to you or that you regularly need to find or identify. We will combine these videos with submissions from other ORBIT contributors to form a large dataset of different objects. This dataset can then be used to develop new AI algorithms to help build apps that will work for blind and visually impaired users all over the world. 

This document includes step-by-step instructions for how to use this app to record videos of different objects in a way that will help us build new AI systems. Because taking videos that can be used for developing AI can be tricky for blind users, these instructions are fairly detailed. Please read them carefully and feel free to revisit the different sections of this guide as often as you need.

## How does AI work?  

Before you begin taking videos, it might help to understand how they will be used. Apps like Seeing AI use Artificial Intelligence, or AI, to automatically recognise the things users shot with their phone camera. To do this, these systems have to be “taught” what to look for by analysing images or videos of things you want to recognise. This is called training the AI. By collecting different examples of an object taken with different views and contexts, you teach the AI what is important and what can be ignored. This is similar to teaching a child a new word by repeating it in different ways. 

However, we also need to measure how well the AI works by seeing how it handles new images that it wasn’t trained on in real-life scenarios. This is called testing the AI. It’s not helpful if the AI works perfectly for identifying your keys sitting on a table by themselves but not when they are next to a phone or cutlery! So, we need to have different videos of objects for training and testing the AI. 

The ORBIT app is designed to collect both training and testing videos. These instructions should help you to record videos that will be used for both purposes. 

# Collecting videos with ORBIT

## Choosing your things

Your first task is to decide what you would like the AI to learn about. To do this, you should choose at least ten things that are important to you. They can be items you regularly need to find or identify, items that easily get misplaced, or items that are difficult to identify by touch alone. For example, your house keys, your backpack, a tin of food, your guide cane, or a wristwatch. Also consider large or immobile things that you might want to recognise. For example, a friend’s door, a car, a colleagues' desk, a specific setting on a household appliance, or a wall plug. Of your things, we suggest that at least two of them are large or immobile things. 

## Choosing where to record 

Your next task is to choose at least six different places where you will record the training videos for the things you can move around. It is important that each of these locations is different so that the app can learn to recognise your things when they are in different places! This can mean surfaces in different rooms of your house or in a public space like a library, in different corners of the same room, in outdoor locations like your garden or garage, in indoor locations with a lot of natural light like near a window, or in locations with no natural light at all, like a cupboard.  

It is okay if you reuse locations and record a training video of one thing on the same surface as the training video of another thing. What is important is that you do not record multiple training videos of the same thing in the same environment. If your things can be easily moved, you can speed up the process by taking several things at once to one location and then taking a training video of each separately before moving them all to the next environment. 

If the items you choose cannot be moved to different environments because they are too large or they are immovable, don’t worry. We’ll give you [specific instructions](#training-videos-for-large-or-immobile-things) for how to deal with these items. 

## The ORBIT Camera app  

The app has two main screens. The first, called the _Things list screen_, is a list of the things that you will take videos of. Selecting one of those things will take you to the second screen, called the _Thing record and review screen_. This is where you record the videos of that thing.  

The things list will be empty on your first use. To add something, select the _Thing name_ text field and enter a name. Once named, you will be taken to the record and review screen. On this screen you choose whether you want the training or testing video collections for this thing, then add videos to that collection. You can also review, re-record, and delete these videos. Here is how the screen is structured: 

1. Buttons for _Train_, _Zoom Out Test_, and _Pan Test_ video collections. Activate to add that kind of videos, or review ones you have already taken. 

2. Add new video button. Brings up the camera controls. Bringing up the camera controls will provide a record button that will start and stop a recording. Upon stop, the camera controls will dismiss and the video will be selected in the video review selector. 

3. Video review selector. Adjust to change the video detailed in the rest of the screen, as follows. 

4. Video recorded date. 

5. Re-record video button. If you wish to re-record, activate to bring up the camera controls. 

6. Orbit dataset status: uploaded. The app will attempt to upload the video to our online repository. The app uses iOS’s built-in background uploading, which will typically wait for power and Wi-Fi before uploading. 

7. Orbit dataset status: checked. We need to check that each video is appropriate. 

8. Orbit dataset status: published. At the end of the data collection period, the ORBIT dataset will be created from our online repository and published. At this point of publishing, any further changes in your app will not change what has been published. 

9. Delete video button. Removes this video from the thing's collection. If the video has not yet been published, this will delete the video from your device and our online repository. Once published, this will only delete the video from your device. 

You can freely navigate between the _Things list screen_ and the _Thing record and review screen_ for each of those things. This means you can add things, and videos of any of those things, as opportunities arise. You do not have to add all the videos for a thing in one go. 

Each screen has a button that brings up a sheet with more information. The _Things list screen_ has _App info_ button that brings up a sheet with this text. The _Thing record and review screen_ has a help button that should bring you to the relevant recording videos instructions. 

# Contacting the ORBIT team
If you have any questions, difficulties, or concerns about using the ORBIT app to collect data, please email us at info@orbit.city.ac.uk

