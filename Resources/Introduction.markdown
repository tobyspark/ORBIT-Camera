# Introduction

Hello and welcome to the ORBIT dataset project! 

We are collecting a dataset to help develop AI recognition apps that will use your mobile phone's camera to find and identify the things that are important to you. For example, has someone moved your house keys? Do you regularly need to identify specific items while out shopping? What about your guide cane - have you forgotten where you put it, or gotten it confused with someone else’s? Maybe you want to recognise the door of a friend’s house? Imagine if you did not have to know exactly where your things were in order to find or identify them again. 

To build these recognition apps, a large dataset of videos taken by blind and visually impaired users is needed. As part of the ORBIT dataset project, you will be asked to take multiple videos of at least ten things that are meaningful to you or that you regularly need to find or identify. We will combine these videos with submissions from other ORBIT contributors to form a large dataset of different objects. This dataset can then be used to develop new AI algorithms to help build apps that will work for blind and visually impaired users all over the world. 

This document includes step-by-step instructions for how to use this app to record videos of different objects in a way that will help us build new AI systems. Because taking videos that can be used for developing AI can be tricky for blind users, these instructions are fairly detailed. Please read them carefully and feel free to revisit the different sections of this guide as often as you need.

## How does AI work?  

Before you begin taking videos, it might help to understand how they will be used. Apps like Seeing AI use Artificial Intelligence, or AI, to automatically recognise the things users shot with their phone camera. To do this, these systems have to be “taught” what to look for by analysing images or videos of things you want to recognise. This is called training the AI. By collecting different examples of an object taken with different views and contexts, you teach the AI what is important and what can be ignored. This is similar to teaching a child a new word by repeating it in different ways. 

However, we also need to measure how well the AI works by seeing how it handles new images that it wasn’t trained on in real-life scenarios. This is called testing the AI. It’s not helpful if the AI works perfectly for identifying your keys sitting on a table by themselves but not when they are next to a phone or cutlery! So, we need to have different videos of objects for training and testing the AI. 

The ORBIT app is designed to collect both training and testing videos. These instructions should help you to record videos that will be used for both purposes.  
